import os
import requests
import re  # we import them into
from bs4 import BeautifulSoup


def extract_subscribers(channel_name: str) -> int:
    '''
    This parser-function extracts available info about channels from their web-pages generated by telegram.
    Using of HTTP can help us avoiding FloodErrors and bans

    return -1 in case of username is not a channel, channel is private or error
    '''
    try:
        r = requests.get("https://t.me/{}".format(channel_name))
        HTML_content = r.content  # store HTML into the variable content
        soup = BeautifulSoup(HTML_content, "html.parser")

        # here we find the right tag with subcsribers
        html_tag_with_subscribers = soup.find(
            "div",
            {"class": "tgme_page_extra"}
        )
        text_number_of_subscribers = html_tag_with_subscribers.text

        # group here means the found match and we want the first one
        number_of_subscribers_raw = re.search(
            "[\\d\\s]+", text_number_of_subscribers).group(0)
        nos = int(number_of_subscribers_raw.replace(" ", ""))

    except Exception as e:
        nos = -1

    return nos


if __name__ == "__main__":
    username = "latinapopacanski"
    # username = "fak_tu"
    username = "kpotoh"
    ns = extract_subscribers(username)
    print(ns)
